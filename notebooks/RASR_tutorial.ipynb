{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config LOADED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PATH = os.getcwd() \n",
    "import sys\n",
    "sys.path.append(PATH + '/../')\n",
    "from utils.config import Config\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import mne\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import make_pipeline\n",
    "sns.set(font_scale=1)\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib widget\n",
    "\n",
    "from timeflux_rasr.estimation import RASR\n",
    "from timeflux_blending.blending import Blending\n",
    "from utils.viz import plotTimeSeries\n",
    "from utils.utils import epoch\n",
    "print(\"Config LOADED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Notebook for rASR implementation \n",
    "It consists in:\n",
    "- loading the eeg signal and events from the *xdf* and *set* files (\n",
    "- visualizing the power spectral density (check dead channels and line noise) \n",
    "- apply a sliding window on both training and test data\n",
    "- train rASR on the training data\n",
    "- apply rASR on test data with blending\n",
    "- compare outcomes with different rASR parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set paths and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/louis/Dropbox/rASR Data/calibration data/sme_1_1.xdf_filt.fdt\n",
      "Reading 0 ... 14999  =      0.000 ...    59.996 secs...\n",
      "training data loaded with 5 channels and 60.0 seconds\n",
      "Reading /Users/louis/Dropbox/rASR Data/filtered/sme_1_1.xdf_filt.fdt\n",
      "Reading 0 ... 247499  =      0.000 ...   989.996 secs...\n",
      "test data loaded with 5 channels and 990.0 seconds\n",
      "Files LOADED\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c05d202bf1744c58dd71e6bf896d276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_files   = '/Users/louis/Dropbox/rASR Data/calibration data/sme_1_1.xdf_filt.set'\n",
    "test_files       = '/Users/louis/Dropbox/rASR Data/filtered/sme_1_1.xdf_filt.set'\n",
    "\n",
    "channels = [\"Fp1\", \"Fp2\", \"T8\", \"Cz\", \"O1\"]\n",
    "\n",
    "mne_eeg_training = mne.io.read_raw_eeglab(training_files, preload=True).pick_channels(channels)\n",
    "print(f\"training data loaded with {len(mne_eeg_training.info['ch_names'])} channels and {mne_eeg_training.times[-1]-mne_eeg_training.times[0]:.1f} seconds\")\n",
    "mne_eeg_test     = mne.io.read_raw_eeglab(test_files, preload=True).pick_channels(channels)\n",
    "print(f\"test data loaded with {len(mne_eeg_test.info['ch_names'])} channels and {mne_eeg_test.times[-1]-mne_eeg_test.times[0]:.1f} seconds\")\n",
    "print(\"Files LOADED\")\n",
    "plt.close(\"all\")\n",
    "plot_args = dict(sfreq=mne_eeg_test.info[\"sfreq\"], ch_names=mne_eeg_test.info[\"ch_names\"], linewidth=0.25, scalings=1e-4)\n",
    "plotTimeSeries(mne_eeg_test.get_data().T, color=\"black\", **plot_args);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set RASR parameters, apply epoching and prepare pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set with epochs of shape (1240, 125, 5)\n",
      "test set with epochs of shape (20615, 125, 5)\n",
      "Pipelines built\n"
     ]
    }
   ],
   "source": [
    "window_len        = 0.5  # in seconds\n",
    "window_overlap    = 0.9  # in ratio of window_len\n",
    "rejection_cutoff  = 20    # in std from the estimated distribution\n",
    "\n",
    "# PREPARE TRAINING AND TEST EPOCHS\n",
    "window_size     = int(mne_eeg_training.info[\"sfreq\"] * window_len)  # epoch length in samples\n",
    "window_interval = int(window_size * (1 - window_overlap))           # step interval in samples\n",
    "\n",
    "\n",
    "# convert training data into epochs\n",
    "X_training = np.swapaxes(epoch(mne_eeg_training.get_data(), window_size, window_interval, axis=-1), 1, 2)\n",
    "print(f\"training set with epochs of shape {X_training.shape}\")\n",
    "\n",
    "# convert test data into epochs\n",
    "X_test = np.swapaxes(epoch(mne_eeg_test.get_data(), window_size, window_interval, axis=-1), 1, 2)\n",
    "print(f\"test set with epochs of shape {X_test.shape}\")\n",
    "\n",
    "rASR_pipeline     = make_pipeline(RASR(rejection_cutoff=rejection_cutoff))\n",
    "blending_pipeline = make_pipeline(Blending(window_overlap=window_size-window_interval, merge=True))\n",
    "print(\"Pipelines built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "## Filter the epochs and reconstruct raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data cleaned and reconstructed \n",
      " fit in 798ms\n",
      " transform in 4805ms (0.23ms/epoch)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rASR_pipeline.fit(X_training)\n",
    "fitting_time = time.time()-start\n",
    "\n",
    "start = time.time()\n",
    "X_test_cleaned = rASR_pipeline.transform(X_test)\n",
    "data_cleaned = blending_pipeline.fit_transform(X_test_cleaned)\n",
    "transform_time = time.time()-start\n",
    "\n",
    "print(f\"data cleaned and reconstructed \\n fit in {fitting_time*1e3 :.0f}ms\\n transform in {transform_time*1e3 :.0f}ms ({transform_time*1e3/X_test.shape[0] :.2f}ms/epoch)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "## Visualize comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd61c674151a416d9fbe30c672e4de25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989.972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b9cb014b4c47729ae049e39eee2455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, continuous_update=False, description='xmin', max=989.972, step=10…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.viz import zoom_effect\n",
    "data = blending_pipeline.fit_transform(X_test)  # reconstruct test data for comparison\n",
    "\n",
    "plt.close(\"all\")\n",
    "# plot data with zoom effect\n",
    "ax2 = plt.subplot(212)\n",
    "plot_args[\"scalings\"]=5e-5\n",
    "\n",
    "plotTimeSeries(data_cleaned, color=\"red\", **plot_args);\n",
    "plotTimeSeries(data, color=\"black\", **plot_args);\n",
    "\n",
    "ax1 = plt.subplot(211)\n",
    "\n",
    "plotTimeSeries(data_cleaned, color=\"red\", **plot_args);\n",
    "plotTimeSeries(data, color=\"black\", **plot_args);\n",
    "ax1.set_xlim(207,215)\n",
    "\n",
    "zoom_effect(ax1,ax2)\n",
    "# add a widget to scroll to the signal (update xlim)\n",
    "from ipywidgets import interact, FloatSlider\n",
    "def update_axis(xmin, xmax):\n",
    "    if xmin<xmax:\n",
    "        ax1.set_xlim(xmin,xmax)\n",
    "\n",
    "Tmax=data.shape[0] / mne_eeg_test.info[\"sfreq\"]\n",
    "print(Tmax)\n",
    "i=FloatSlider(min=0, max=Tmax, step=10, continuous_update=False)\n",
    "ii=FloatSlider(min=0, max=Tmax, step=10, continuous_update=False)\n",
    "from ipywidgets import FloatSlider\n",
    "interact(update_axis,xmin=i, xmax=ii);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeflux_rasr-env",
   "language": "python",
   "name": "timeflux_rasr-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
